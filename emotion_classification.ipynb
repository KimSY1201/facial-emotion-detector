{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ EMOTION CLASSIFICATION - ANGRY ]<hr>\n",
    "\n",
    "- 분류/지도학습\n",
    "- DNN MODEL\n",
    "- ANGRY 판별 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩 \n",
    "import torch                                            ## 텐서 및 기본 함수들 모듈\n",
    "import torch.nn as nn                                   ## 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F                         ## 인공신경망 관련 함수들 모듈\n",
    "import torch.optim as optim                             ## 인공신경망 관련 최적화 모듈\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  ## 학습률 조정 \n",
    "\n",
    "from torchinfo import summary                           ## 모델 정보 및 구조 확인 모듈\n",
    "from torchmetrics.classification import *               ## 모델 성능 지표 관련 모듈\n",
    "\n",
    "from torchvision.datasets import ImageFolder            ## 이미지용 데이터셋 생성 모듈\n",
    "from torch.utils.data import DataLoader                 ## 데이터 셋 관련 모듈\n",
    "from torch.utils.data import Subset, random_split       \n",
    "from torchvision.transforms import transforms           ## 이미지 전처리 및 증강 모듈\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt                         ## 이미지 시각화 \n",
    "\n",
    "from utils import get_custom_subset, count_images_in_subset, relabel_dataset, FocalLoss, predict_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DNNmodel import EmotionDNN\n",
    "from model_funcion import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 이미지 증강 ]<hr>\n",
    "- angry 46000장\n",
    "- angry 제외한 46000장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as tf\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 LIB 충돌 방지를 위한 환경 설정\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = './data/archive/MMAFEDB/train/angry/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COUNT = 30000  # 목표 이미지 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 이미지 개수: 13000 / 30000\n",
      "현재 이미지 개수: 14000 / 30000\n",
      "현재 이미지 개수: 15000 / 30000\n",
      "현재 이미지 개수: 16000 / 30000\n",
      "현재 이미지 개수: 17000 / 30000\n",
      "현재 이미지 개수: 18000 / 30000\n",
      "현재 이미지 개수: 19000 / 30000\n",
      "현재 이미지 개수: 20000 / 30000\n",
      "현재 이미지 개수: 21000 / 30000\n",
      "현재 이미지 개수: 22000 / 30000\n",
      "현재 이미지 개수: 23000 / 30000\n",
      "현재 이미지 개수: 24000 / 30000\n",
      "현재 이미지 개수: 25000 / 30000\n",
      "현재 이미지 개수: 26000 / 30000\n",
      "현재 이미지 개수: 27000 / 30000\n",
      "현재 이미지 개수: 28000 / 30000\n",
      "현재 이미지 개수: 29000 / 30000\n",
      "현재 이미지 개수: 30000 / 30000\n",
      "\n",
      " 총 30000개의 이미지가 ./data/archive/MMAFEDB/train/angry/에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 현재 이미지 목록 가져오기\n",
    "images = os.listdir(IMG_DIR)\n",
    "current_count = len(images)\n",
    "\n",
    "# 데이터 증강 정의\n",
    "augmentation = tf.Compose([\n",
    "    tf.RandomRotation(degrees=(-30, 30), expand=True),   # 랜덤 회전\n",
    "    tf.RandomHorizontalFlip(p=0.5),                      # 좌우 반전 (50% 확률)\n",
    "    tf.RandomVerticalFlip(p=0.5),                        # 상하 반전 (50% 확률)\n",
    "    tf.ToTensor()\n",
    "])\n",
    "\n",
    "def save_image(tensor_img, save_path):\n",
    "    img = tf.ToPILImage()(tensor_img)\n",
    "    img.save(save_path)\n",
    "\n",
    "# 기존 이미지 저장하기\n",
    "for img_name in images:\n",
    "    src_path = os.path.join(IMG_DIR, img_name)\n",
    "    dst_path = os.path.join(IMG_DIR, img_name)\n",
    "    img = Image.open(src_path).convert('L')  # Grayscale로 변환\n",
    "    img.save(dst_path)\n",
    "\n",
    "# 데이터 증강으로 목표 개수까지 증가시키기\n",
    "while current_count < TARGET_COUNT:\n",
    "    img_name = random.choice(images)\n",
    "    img_path = os.path.join(IMG_DIR, img_name)\n",
    "    \n",
    "    with Image.open(img_path) as img:\n",
    "        img = img.convert('L')  # Grayscale로 변환\n",
    "        tensor_img = tf.ToTensor()(img)\n",
    "        \n",
    "        # 증강 처리\n",
    "        augmented_img = augmentation(img)\n",
    "        \n",
    "        # 이미지 저장\n",
    "        new_img_name = f'augmented_{current_count}.png'\n",
    "        save_path = os.path.join(IMG_DIR, new_img_name)\n",
    "        save_image(augmented_img, save_path)\n",
    "        \n",
    "        current_count += 1\n",
    "\n",
    "    if current_count % 1000 == 0:\n",
    "        print(f'현재 이미지 개수: {current_count} / {TARGET_COUNT}')\n",
    "\n",
    "print(f'\\n 총 {current_count}개의 이미지가 {IMG_DIR}에 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 데이터 로딩 및 데이터셋 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 준비\n",
    "TRAIN_ROOT ='./data/archive/MMAFEDB/train/'\n",
    "VALID_ROOT ='./data/archive/MMAFEDB/valid/'\n",
    "TEST_ROOT ='./data/archive/MMAFEDB/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1-2] 이미지 데이터 로딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), # Grayscale 변환\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),                        # (1, 48, 48)\n",
    "    transforms.Normalize((0.5,), (0.5,))          # 채널 1개 -> 평균, 표준편차도 1개씩\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - 이미지 데이터 로딩 \n",
    "TRAINDS = ImageFolder(root=TRAIN_ROOT,\n",
    "                        transform=train_transform)\n",
    "VALIDDS = ImageFolder(root=VALID_ROOT, \n",
    "                    transform=valid_transform)\n",
    "TESTDS = ImageFolder(root=TEST_ROOT, \n",
    "                    transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX_TO_CLASS => {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "## - 클래스 변환 데이터 \n",
    "IDX_TO_CLASS = {v:k for k, v in TRAINDS.class_to_idx.items()}\n",
    "print(f'IDX_TO_CLASS => {IDX_TO_CLASS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgDataset 개수 : 121908개\n",
      "imgDataset 분류 : {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "- angry      개수 : 30000개, 24.60872133083965\n",
      "- disgust      개수 : 4433개, 3.636348721987072\n",
      "- fear      개수 : 9163개, 7.516323785149456\n",
      "- happy      개수 : 28592개, 23.453752009712243\n",
      "- neutral      개수 : 29384개, 24.10342225284641\n",
      "- sad      개수 : 12223개, 10.0264133608951\n",
      "- surprise      개수 : 8113개, 6.6550185385700695\n"
     ]
    }
   ],
   "source": [
    "## - 데이터 확인\n",
    "print(f'imgDataset 개수 : {len(TRAINDS.targets)}개')\n",
    "print(f'imgDataset 분류 : {TRAINDS.class_to_idx}')\n",
    "print(f'- angry      개수 : {TRAINDS.targets.count(0)}개, {(TRAINDS.targets.count(0)/len(TRAINDS.targets))*100}')\n",
    "print(f'- disgust      개수 : {TRAINDS.targets.count(1)}개, {(TRAINDS.targets.count(1)/len(TRAINDS.targets))*100}')\n",
    "print(f'- fear      개수 : {TRAINDS.targets.count(2)}개, {(TRAINDS.targets.count(2)/len(TRAINDS.targets))*100}')\n",
    "print(f'- happy      개수 : {TRAINDS.targets.count(3)}개, {(TRAINDS.targets.count(3)/len(TRAINDS.targets))*100}')\n",
    "print(f'- neutral      개수 : {TRAINDS.targets.count(4)}개, {(TRAINDS.targets.count(4)/len(TRAINDS.targets))*100}')\n",
    "print(f'- sad      개수 : {TRAINDS.targets.count(5)}개, {(TRAINDS.targets.count(5)/len(TRAINDS.targets))*100}')\n",
    "print(f'- surprise      개수 : {TRAINDS.targets.count(6)}개, {(TRAINDS.targets.count(6)/len(TRAINDS.targets))*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터셋에 대해 라벨 변경하기\n",
    "relabel_dataset(TRAINDS)\n",
    "relabel_dataset(VALIDDS)\n",
    "relabel_dataset(TESTDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨이 제대로 변경되었는지 확인하기\n",
    "train_labels = [label for _, label in TRAINDS.samples]\n",
    "test_labels = [label for _, label in TESTDS.samples]\n",
    "valid_labels = [label for _, label in VALIDDS.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset - 0 (Others): 91908, 1 (Angry): 30000\n",
      "Test Dataset - 0 (Others): 16315, 1 (Angry): 1041\n",
      "Valid Dataset - 0 (Others): 16339, 1 (Angry): 1017\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Dataset - 0 (Others): {train_labels.count(0)}, 1 (Angry): {train_labels.count(1)}\")\n",
    "print(f\"Test Dataset - 0 (Others): {test_labels.count(0)}, 1 (Angry): {test_labels.count(1)}\")\n",
    "print(f\"Valid Dataset - 0 (Others): {valid_labels.count(0)}, 1 (Angry): {valid_labels.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 데이터 불균형 -> 균형으로 맞추기 ]<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_include_all_images = ['angry', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_custom_subset, count_images_in_subset, relabel_dataset\n",
    "\n",
    "train_subset = get_custom_subset(TRAINDS, 5000, classes_to_include_all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'VALIDDS.class_to_idx'에서 클래스별 인덱스를 가져옵니다.\n",
    "idx_to_classes = {v: k for k, v in VALIDDS.class_to_idx.items()}\n",
    "\n",
    "# 각 클래스의 샘플 인덱스를 선택하여 리스트에 저장\n",
    "selected_indices = []\n",
    "for class_idx in range(len(idx_to_classes)):\n",
    "    # 'VALIDDS.targets'에서 해당 클래스 인덱스를 가진 샘플들의 인덱스를 선택\n",
    "    class_indices = [i for i, target in enumerate(VALIDDS.targets) if target == class_idx]\n",
    "    selected_indices.extend(class_indices)  # 각 클래스의 인덱스를 모두 추가\n",
    "\n",
    "# 전체 데이터셋의 서브셋을 생성\n",
    "valid_subset = Subset(VALIDDS, selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: 30000 images\n",
      "disgust: 4433 images\n",
      "fear: 5000 images\n",
      "happy: 5000 images\n",
      "neutral: 5000 images\n",
      "sad: 5000 images\n",
      "surprise: 5000 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# train_subset에서 각 감정 클래스별 이미지 수 출력\n",
    "count_images_in_subset(train_subset, TRAINDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로더 준비<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 59433 images\n",
      "Validation data: 17356 images\n"
     ]
    }
   ],
   "source": [
    "# 데이터로더 설정\n",
    "TRAINDL= DataLoader(train_subset, batch_size=1000, shuffle=True, generator=torch.Generator().manual_seed(42))\n",
    "VALIDDL = DataLoader(valid_subset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"Training data: {len(train_subset)} images\")\n",
    "print(f\"Validation data: {len(valid_subset)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x230331b96b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 PyTorch 난수 생성기 시드 설정, 전역적으로 모든 랜덤 생성기의 시드를 설정 즉, PyTorch의 모든 연산에 영향\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 48, 48]) tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
      "disgust\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 체크\n",
    "img, target = next(iter(TRAINDL))\n",
    "print(img.shape, target)\n",
    "\n",
    "\n",
    "print(IDX_TO_CLASS[target[0].item()])  # 첫 번째 이미지의 클래스 이름 \n",
    "\n",
    "# 첫 번째 이미지를 시각화 (img의 크기가 [batch_size, C, H, W] 형식일 경우)\n",
    "plt.imshow(img[0].permute(1, 2, 0))  # 이미지는 [C, H, W] 형식이므로, [H, W, C]로 변환하여 표시\n",
    "plt.title(IDX_TO_CLASS[target[0].item()])  # 첫 번째 이미지의 클래스 이름을 제목으로 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 모델 정의 및 클래스 설계 ]<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmotionDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 입력 크기가 48x48인 이미지를 처리하는 레이어로, 48 * 48 = 2304\n",
    "        self.in_layer   = nn.Flatten()  # 3D (BS, H, W) -> 2D (BS, H*W)\n",
    "        \n",
    "        # 첫 번째 Hidden Layer + 배치 정규화 (Batch Normalization)\n",
    "        self.hd_layer1  = nn.Linear(2304, 512)  # 2304 -> 512\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)  # 배치 정규화\n",
    "        \n",
    "        # 두 번째 Hidden Layer + 배치 정규화\n",
    "        self.hd_layer2  = nn.Linear(512, 256)   # 512 -> 256\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)  # 배치 정규화\n",
    "        \n",
    "        # 세 번째 Hidden Layer\n",
    "        self.hd_layer3  = nn.Linear(256, 130)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(130)\n",
    "        \n",
    "        self.out_layer  = nn.Linear(130, 1)\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 데이터의 크기 출력 (배치 크기, 높이, 너비)\n",
    "        # print(f'Input data shape: {data.shape}')\n",
    "        \n",
    "        # Flatten (3D -> 2D)\n",
    "        out = self.in_layer(data)\n",
    "        # print(f'After Flatten: {out.shape}')\n",
    "\n",
    "        # 첫 번째 Hidden Layer + 배치 정규화 + Dropout\n",
    "        out = F.relu(self.hd_layer1(out))\n",
    "        out = self.batch_norm1(out)  # 배치 정규화\n",
    "        out = self.drop_layer(out)\n",
    "\n",
    "        # 두 번째 Hidden Layer + 배치 정규화 + Dropout\n",
    "        out = F.relu(self.hd_layer2(out))\n",
    "        out = self.batch_norm2(out)  # 배치 정규화\n",
    "        out = self.drop_layer(out)\n",
    "\n",
    "        # 세 번째 Hidden Layer\n",
    "        out = F.relu(self.hd_layer3(out))\n",
    "        out = self.batch_norm3(out)\n",
    "        out = self.drop_layer(out)\n",
    "\n",
    "\n",
    "\n",
    "        # Output Layer\n",
    "        out = self.out_layer(out)\n",
    "        \n",
    "        # print(f'Output shape: {out.shape}')\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EmotionDNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## 모델 구조 확인 \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary \n\u001b[1;32m----> 4\u001b[0m m1 \u001b[38;5;241m=\u001b[39m \u001b[43mEmotionDNN\u001b[49m()\n\u001b[0;32m      5\u001b[0m summary(m1, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EmotionDNN' is not defined"
     ]
    }
   ],
   "source": [
    "## 모델 구조 확인 \n",
    "from torchinfo import summary \n",
    "\n",
    "m1 = EmotionDNN()\n",
    "summary(m1, input_size=(100, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmotionDNN(\n",
      "  (in_layer): Flatten(start_dim=1, end_dim=-1)\n",
      "  (hd_layer1): Linear(in_features=2304, out_features=512, bias=True)\n",
      "  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (hd_layer2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (hd_layer3): Linear(in_features=256, out_features=130, bias=True)\n",
      "  (batch_norm3): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out_layer): Linear(in_features=130, out_features=1, bias=True)\n",
      "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 모델 학습 ]<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 관련 함수\n",
    "## --------------------------------------------------------------\n",
    "## - 검증 함수 : 테스트 또는 검증용 데이터셋 사용하는 함수 \n",
    "##              W,b 업데이트 안함\n",
    "## --------------------------------------------------------------\n",
    "def evaluate(model, testDL, loss_fn, score_fn, n_iter):\n",
    "    # 에포크 단위로 검증 => 검증 모드\n",
    "    model.eval()\n",
    "\n",
    "    # W, b가 업데이트 해제\n",
    "    with torch.no_grad():\n",
    "        T_LOSS, T_ACC = 0, 0\n",
    "        for feature, target in testDL:\n",
    "            # 학습 진행\n",
    "            pre_y = model(feature)\n",
    "\n",
    "            # 손실 계산\n",
    "            target = target.float().unsqueeze(1)  # target을 [batch_size, 1] 형태로 변환\n",
    "            loss = loss_fn(pre_y, target)\n",
    "        \n",
    "            # 정확도 계산: 시그모이드 적용 후 0.5 기준으로 임계값 처리\n",
    "            pred = torch.sigmoid(pre_y)  # 로짓을 확률로 변환\n",
    "            pred = (pred >= 0.5).float()  # 확률을 0 또는 1로 변환 (0.5 기준)\n",
    "\n",
    "            acc = (pred == target).float().mean()  # 정확도 계산\n",
    "\n",
    "            T_LOSS += loss.item()\n",
    "            T_ACC  += acc.item()\n",
    "\n",
    "    return T_LOSS/n_iter, T_ACC/n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy\n",
    "\n",
    "def training(model, trainDL, optimizer, loss_fn, acc_fn, n_iter):\n",
    "    model.train()\n",
    "\n",
    "    E_LOSS, E_ACC, E_SCORE = 0, 0, 0\n",
    "    for feature, target in trainDL:\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE).float().unsqueeze(1)\n",
    "        \n",
    "        # 가중치 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 예측값 계산 (로짓 값)\n",
    "        pre_y = model(feature)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_fn(pre_y, target)\n",
    "\n",
    "        # 모델 출력값을 Sigmoid 함수로 확률로 변환\n",
    "        prob = torch.sigmoid(pre_y)\n",
    "\n",
    "        # 예측 값(0 또는 1)으로 변환 (명시적으로 threshold=0.5 적용)\n",
    "        pred = (prob > 0.5).float()\n",
    "\n",
    "        # 정확도와 F1 Score 계산\n",
    "        #score = score_fn(pred, target.int())\n",
    "        \n",
    "        # 정확도 계산 (acc_fn 사용)\n",
    "        acc = acc_fn(pred, target.int())  # BinaryAccuracy 인스턴스 사용\n",
    "        \n",
    "        # 역전파 진행\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        E_LOSS += loss.item()\n",
    "        # E_SCORE += score.item()\n",
    "        E_ACC  += acc.item()\n",
    "\n",
    "    return E_LOSS / n_iter, E_ACC / n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE => cpu\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "## 학습 설정\n",
    "EPOCHS      = 50\n",
    "BATCH_SIZE  = 1000\n",
    "T_ITERATION = ceil(len(TRAINDS) / BATCH_SIZE)\n",
    "V_ITERATION = ceil(len(TESTDS) / BATCH_SIZE)\n",
    "\n",
    "## 최적화 설정\n",
    "LR          = 0.0005\n",
    "PAT_CNT     = 10 # 성능 향상이 없을 때 10번의 에폭 후 중단\n",
    "CLASSES     = len(TRAINDS.classes)\n",
    "\n",
    "## 학습 및 데이터 로딩 실행 위치/저장 위치\n",
    "DEVICE      = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'DEVICE => {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import *\n",
    "\n",
    "## 인스턴스 생성\n",
    "GEN = torch.Generator().manual_seed(42) # 랜덤 시드 고정\n",
    "\n",
    "MODEL       = EmotionDNN()\n",
    "OPTIMIZER   = optim.Adam(MODEL.parameters(), lr=LR)\n",
    "SCHEDULER   = ReduceLROnPlateau(OPTIMIZER, mode='min', patience=PAT_CNT)\n",
    "\n",
    "\n",
    "LOSS_FN     = FocalLoss()\n",
    "SCORE_FN    = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 학습 진행  : 모델 또는 가중치 저장 + 성능이 더이상 좋아지지 않으면 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 경로 설정\n",
    "MODEL_DIR  = './models/'\n",
    "MODEL_FILE = 'EmotionDNN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH[0/50]----------------\n",
      "- TRAIN_LOSS 0.01927  ACC 0.35526\n",
      "- VALID_LOSS 0.02326  ACC 0.92964\n",
      "\n",
      "EPOCH[1/50]----------------\n",
      "- TRAIN_LOSS 0.01510  ACC 0.37490\n",
      "- VALID_LOSS 0.02442  ACC 0.93148\n",
      "\n",
      "EPOCH[2/50]----------------\n",
      "- TRAIN_LOSS 0.01403  ACC 0.38242\n",
      "- VALID_LOSS 0.02509  ACC 0.92745\n",
      "\n",
      "EPOCH[3/50]----------------\n",
      "- TRAIN_LOSS 0.01354  ACC 0.38571\n",
      "- VALID_LOSS 0.02391  ACC 0.93159\n",
      "\n",
      "EPOCH[4/50]----------------\n",
      "- TRAIN_LOSS 0.01325  ACC 0.38812\n",
      "- VALID_LOSS 0.02400  ACC 0.92973\n",
      "\n",
      "EPOCH[5/50]----------------\n",
      "- TRAIN_LOSS 0.01308  ACC 0.38945\n",
      "- VALID_LOSS 0.02488  ACC 0.91930\n",
      "\n",
      "EPOCH[6/50]----------------\n",
      "- TRAIN_LOSS 0.01284  ACC 0.39196\n",
      "- VALID_LOSS 0.02432  ACC 0.90938\n",
      "\n",
      "EPOCH[7/50]----------------\n",
      "- TRAIN_LOSS 0.01278  ACC 0.39215\n",
      "- VALID_LOSS 0.02450  ACC 0.90698\n",
      "\n",
      "EPOCH[8/50]----------------\n",
      "- TRAIN_LOSS 0.01259  ACC 0.39470\n",
      "- VALID_LOSS 0.02382  ACC 0.90632\n",
      "\n",
      "EPOCH[9/50]----------------\n",
      "- TRAIN_LOSS 0.01237  ACC 0.39697\n",
      "- VALID_LOSS 0.02415  ACC 0.90248\n",
      "\n",
      "EPOCH[10/50]----------------\n",
      "- TRAIN_LOSS 0.01233  ACC 0.39757\n",
      "- VALID_LOSS 0.02564  ACC 0.88547\n",
      "\n",
      "EPOCH[11/50]----------------\n",
      "- TRAIN_LOSS 0.01223  ACC 0.39813\n",
      "- VALID_LOSS 0.02428  ACC 0.89454\n",
      "\n",
      "EPOCH[12/50]----------------\n",
      "- TRAIN_LOSS 0.01195  ACC 0.40123\n",
      "- VALID_LOSS 0.02344  ACC 0.89837\n",
      "\n",
      "EPOCH[13/50]----------------\n",
      "- TRAIN_LOSS 0.01181  ACC 0.40314\n",
      "- VALID_LOSS 0.02398  ACC 0.88950\n",
      "\n",
      "EPOCH[14/50]----------------\n",
      "- TRAIN_LOSS 0.01173  ACC 0.40320\n",
      "- VALID_LOSS 0.02347  ACC 0.89131\n",
      "\n",
      "EPOCH[15/50]----------------\n",
      "- TRAIN_LOSS 0.01170  ACC 0.40335\n",
      "- VALID_LOSS 0.02349  ACC 0.89033\n",
      "\n",
      "EPOCH[16/50]----------------\n",
      "- TRAIN_LOSS 0.01163  ACC 0.40422\n",
      "- VALID_LOSS 0.02381  ACC 0.88527\n",
      "\n",
      "EPOCH[17/50]----------------\n",
      "- TRAIN_LOSS 0.01153  ACC 0.40591\n",
      "- VALID_LOSS 0.02373  ACC 0.88560\n",
      "\n",
      "EPOCH[18/50]----------------\n",
      "- TRAIN_LOSS 0.01151  ACC 0.40567\n",
      "- VALID_LOSS 0.02341  ACC 0.88741\n",
      "\n",
      "EPOCH[19/50]----------------\n",
      "- TRAIN_LOSS 0.01145  ACC 0.40583\n",
      "- VALID_LOSS 0.02383  ACC 0.87991\n",
      "\n",
      "EPOCH[20/50]----------------\n",
      "- TRAIN_LOSS 0.01142  ACC 0.40658\n",
      "- VALID_LOSS 0.02396  ACC 0.87903\n",
      "\n",
      "EPOCH[21/50]----------------\n",
      "- TRAIN_LOSS 0.01137  ACC 0.40691\n",
      "- VALID_LOSS 0.02406  ACC 0.87641\n",
      "\n",
      "EPOCH[22/50]----------------\n",
      "- TRAIN_LOSS 0.01133  ACC 0.40785\n",
      "- VALID_LOSS 0.02353  ACC 0.88118\n",
      "\n",
      "EPOCH[23/50]----------------\n",
      "- TRAIN_LOSS 0.01122  ACC 0.40875\n",
      "- VALID_LOSS 0.02371  ACC 0.87887\n",
      "\n",
      "EPOCH[24/50]----------------\n",
      "- TRAIN_LOSS 0.01115  ACC 0.40979\n",
      "- VALID_LOSS 0.02323  ACC 0.88405\n",
      "\n",
      "EPOCH[25/50]----------------\n",
      "- TRAIN_LOSS 0.01116  ACC 0.40921\n",
      "- VALID_LOSS 0.02323  ACC 0.88427\n",
      "\n",
      "EPOCH[26/50]----------------\n",
      "- TRAIN_LOSS 0.01116  ACC 0.40840\n",
      "- VALID_LOSS 0.02328  ACC 0.88344\n",
      "\n",
      "EPOCH[27/50]----------------\n",
      "- TRAIN_LOSS 0.01116  ACC 0.40958\n",
      "- VALID_LOSS 0.02337  ACC 0.88216\n",
      "\n",
      "EPOCH[28/50]----------------\n",
      "- TRAIN_LOSS 0.01112  ACC 0.40980\n",
      "- VALID_LOSS 0.02314  ACC 0.88328\n",
      "\n",
      "EPOCH[29/50]----------------\n",
      "- TRAIN_LOSS 0.01117  ACC 0.40863\n",
      "- VALID_LOSS 0.02307  ACC 0.88505\n",
      "\n",
      "EPOCH[30/50]----------------\n",
      "- TRAIN_LOSS 0.01116  ACC 0.40885\n",
      "- VALID_LOSS 0.02272  ACC 0.88622\n",
      "\n",
      "EPOCH[31/50]----------------\n",
      "- TRAIN_LOSS 0.01112  ACC 0.40917\n",
      "- VALID_LOSS 0.02310  ACC 0.88356\n",
      "\n",
      "EPOCH[32/50]----------------\n",
      "- TRAIN_LOSS 0.01116  ACC 0.40897\n",
      "- VALID_LOSS 0.02320  ACC 0.88345\n",
      "\n",
      "EPOCH[33/50]----------------\n",
      "- TRAIN_LOSS 0.01110  ACC 0.41038\n",
      "- VALID_LOSS 0.02335  ACC 0.88057\n",
      "\n",
      "EPOCH[34/50]----------------\n",
      "- TRAIN_LOSS 0.01111  ACC 0.41008\n",
      "- VALID_LOSS 0.02369  ACC 0.87747\n",
      "\n",
      "EPOCH[35/50]----------------\n",
      "- TRAIN_LOSS 0.01105  ACC 0.41048\n",
      "- VALID_LOSS 0.02358  ACC 0.87864\n",
      "\n",
      "EPOCH[36/50]----------------\n",
      "- TRAIN_LOSS 0.01105  ACC 0.41046\n",
      "- VALID_LOSS 0.02306  ACC 0.88278\n",
      "\n",
      "EPOCH[37/50]----------------\n",
      "- TRAIN_LOSS 0.01110  ACC 0.40960\n",
      "- VALID_LOSS 0.02313  ACC 0.88306\n",
      "\n",
      "EPOCH[38/50]----------------\n",
      "- TRAIN_LOSS 0.01108  ACC 0.40978\n",
      "- VALID_LOSS 0.02306  ACC 0.88262\n",
      "\n",
      "EPOCH[39/50]----------------\n",
      "- TRAIN_LOSS 0.01104  ACC 0.41056\n",
      "- VALID_LOSS 0.02358  ACC 0.87714\n",
      "\n",
      "EPOCH[40/50]----------------\n",
      "- TRAIN_LOSS 0.01108  ACC 0.41045\n",
      "- VALID_LOSS 0.02301  ACC 0.88416\n",
      "40--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[41/50]----------------\n",
      "- TRAIN_LOSS 0.01103  ACC 0.41037\n",
      "- VALID_LOSS 0.02330  ACC 0.88034\n",
      "41--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[42/50]----------------\n",
      "- TRAIN_LOSS 0.01105  ACC 0.41045\n",
      "- VALID_LOSS 0.02347  ACC 0.87901\n",
      "42--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[43/50]----------------\n",
      "- TRAIN_LOSS 0.01101  ACC 0.41067\n",
      "- VALID_LOSS 0.02325  ACC 0.88127\n",
      "43--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[44/50]----------------\n",
      "- TRAIN_LOSS 0.01104  ACC 0.40985\n",
      "- VALID_LOSS 0.02300  ACC 0.88372\n",
      "44--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[45/50]----------------\n",
      "- TRAIN_LOSS 0.01099  ACC 0.41120\n",
      "- VALID_LOSS 0.02333  ACC 0.87990\n",
      "45--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[46/50]----------------\n",
      "- TRAIN_LOSS 0.01102  ACC 0.41068\n",
      "- VALID_LOSS 0.02346  ACC 0.87808\n",
      "46--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[47/50]----------------\n",
      "- TRAIN_LOSS 0.01103  ACC 0.40986\n",
      "- VALID_LOSS 0.02309  ACC 0.88305\n",
      "47--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[48/50]----------------\n",
      "- TRAIN_LOSS 0.01100  ACC 0.41087\n",
      "- VALID_LOSS 0.02320  ACC 0.88001\n",
      "48--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n",
      "\n",
      "EPOCH[49/50]----------------\n",
      "- TRAIN_LOSS 0.01106  ACC 0.41066\n",
      "- VALID_LOSS 0.02341  ACC 0.87792\n",
      "49--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]\n"
     ]
    }
   ],
   "source": [
    "## 학습 관련 모듈 로딩\n",
    "# from utils import * \n",
    "\n",
    "# 에포크 : DS 처음부터 ~ 끝까지 학습  \n",
    "HIST ={'Train':[[],[]], 'Valid':[[],[]]} \n",
    "\n",
    "# 모델 저장을 위한 기준값 저장 변수 \n",
    "BEST_ACC = 0\n",
    "\n",
    "# 조기종료 위한 기준값 저장 변수\n",
    "EARLY_STOP = 3\n",
    "\n",
    "# 에포크 단위 학습/검증 진행 \n",
    "for epoch in range(EPOCHS):\n",
    "    trainLoss, trainAcc = training(MODEL, TRAINDL, OPTIMIZER, LOSS_FN, SCORE_FN, T_ITERATION)\n",
    "    validLoss, validAcc = evaluate(MODEL, VALIDDL, LOSS_FN, SCORE_FN, V_ITERATION)\n",
    "\n",
    "    ## 모델 저장\n",
    "    # if BEST_ACC < validAcc:   # 0 < 0.1212  ==>  0.1212 < 현재 valacc\n",
    "    #     #torch.save(MODEL, MODEL_DIR+MODEL_FILE)\n",
    "    #     torch.save(MODEL, f'{MODEL_DIR}fashion_epoch{epoch}_{validAcc:.3f}.pt')\n",
    "    #     BEST_ACC = validAcc\n",
    "\n",
    "    ## 모델 층별 가중치+바이어스 저장\n",
    "    if BEST_ACC < validAcc:   # 0 < 0.1212  ==>  0.1212 < 현재 valacc\n",
    "        #torch.save(MODEL.state_dict(), MODEL_DIR+MODEL_FILE)\n",
    "        torch.save(MODEL.state_dict(), f'{MODEL_DIR}emotion_2st_weights_epoch{epoch}_{validAcc:.3f}.pt')\n",
    "        BEST_ACC = validAcc\n",
    "\n",
    "    # 학습 상태 저장\n",
    "    HIST['Train'][0].append(trainLoss) \n",
    "    HIST['Train'][1].append(trainAcc) \n",
    "    \n",
    "    HIST['Valid'][0].append(validLoss) \n",
    "    HIST['Valid'][1].append(validAcc) \n",
    "\n",
    "    # 학습 상태 시각화\n",
    "    print(f'\\nEPOCH[{epoch}/{EPOCHS}]----------------')\n",
    "    print(f'- TRAIN_LOSS {trainLoss:.5f}  ACC {trainAcc:.5f}')\n",
    "    print(f'- VALID_LOSS {validLoss:.5f}  ACC {validAcc:.5f}')\n",
    "    \n",
    "    # 조기종료 체크\n",
    "    SCHEDULER.step(validLoss)\n",
    "    \n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience:\n",
    "        EARLY_STOP -= 1\n",
    "        \n",
    "    if not EARLY_STOP:\n",
    "        print(f'{epoch}--[EPOCHS : 성능 개선이 없어서 조기 종료합니다.]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 모델 활용 ]<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장된 층별 가중치와바이어스 로딩 \n",
    "WEIGHTS_FILE = MODEL_DIR+'emotion_weights_epoch11_0.943.pt'\n",
    "\n",
    "model = EmotionDNN()\n",
    "states=torch.load(WEIGHTS_FILE, weights_only=True)\n",
    "model.load_state_dict(states)\n",
    "\n",
    "MODEL_FILE = model.load_state_dict(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmotionDNN(\n",
       "  (in_layer): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hd_layer1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hd_layer2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hd_layer3): Linear(in_features=256, out_features=130, bias=True)\n",
       "  (batch_norm3): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (out_layer): Linear(in_features=130, out_features=1, bias=True)\n",
       "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = './models/'\n",
    "\n",
    "# 모델 정의 및 가중치 로드\n",
    "WEIGHTS_FILE = MODEL_DIR+'emotion_weights_epoch11_0.943.pt'\n",
    "\n",
    "\n",
    "model = EmotionDNN()\n",
    "\n",
    "states=torch.load(WEIGHTS_FILE, weights_only=True)\n",
    "model.load_state_dict(states)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# # 모델 객체 전체 저장\n",
    "# torch.save(model, 'Emotion_DNNMODEL.pt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 예측 ]<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'C:\\Users\\KDT-37\\Desktop\\KDT_7\\10_DL\\project\\data\\archive\\MMAFEDB\\valid\\happy\\98Exp3angry_actor_653.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 감정: not angry, 확률: 0.73\n"
     ]
    }
   ],
   "source": [
    "result, confidence = predict_image(model, image_path)\n",
    "print(f\"예측된 감정: {result}, 확률: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'C:\\Users\\KDT-37\\Desktop\\KDT_7\\10_DL\\project\\1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 감정: not angry, 확률: 0.63\n"
     ]
    }
   ],
   "source": [
    "result, confidence = predict_image(model, image_path)\n",
    "print(f\"예측된 감정: {result}, 확률: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
